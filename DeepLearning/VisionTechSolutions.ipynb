{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIDKIRvZUow/18iZ3NKyF2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mighty-mass/ai-engineer-course/blob/main/DeepLearning/VisionTechSolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Riconoscimento di animali per auto a guida autonoma\n",
        "VisionTech Solutions vuole sviluppare un sistema di riconoscimento automatico delle immagini per distinguere tra veicoli e animali, con l'obiettivo di ottimizzare le operazioni di monitoraggio della fauna nelle aree urbane, evitando incidenti stradali e proteggendo sia gli animali che i veicoli.\n",
        "\n",
        "VisionTech Solutions collabora con le amministrazioni comunali per implementare un sistema di monitoraggio in tempo reale nelle città, utilizzando telecamere installate lungo le strade per identificare e classificare veicoli e animali. Questo sistema aiuterà a prevenire incidenti stradali causati dall'attraversamento improvviso di animali, avvisando i guidatori tramite segnali stradali elettronici.\n",
        "\n",
        "Benefici:\n",
        "\n",
        "1. Automazione dei Processi:\n",
        "- Riduzione del tempo e delle risorse per monitorare manualmente le aree urbane.\n",
        "- Rilevamento automatico e in tempo reale di animali e veicoli.\n",
        "2. Aumento della Precisione:\n",
        "- Utilizzo di una rete neurale convoluzionale (CNN) per garantire alta precisione nella classificazione delle immagini.\n",
        "- Minimizzazione degli errori umani.\n",
        "3. Efficienza Operativa:\n",
        "- Processamento rapido e accurato di grandi volumi di dati, migliorando la risposta agli eventi.\n",
        "- Maggiore sicurezza per i cittadini e riduzione dei danni ai veicoli.\n",
        "4. Applicazioni Multiple:\n",
        "- Sorveglianza e monitoraggio del traffico.\n",
        "- Analisi del comportamento animale nelle aree urbane.\n",
        "- Utilizzo dei dati per migliorare le politiche di sicurezza stradale.\n",
        "\n",
        "## Dettagli del Progetto:\n",
        "\n",
        "1. Dataset:\n",
        "- Utilizzo del dataset CIFAR, contenente migliaia di immagini etichettate in varie categorie, inclusi veicoli e animali.\n",
        "2. Algoritmo:\n",
        "- Implementazione di una rete neurale convoluzionale (CNN) per l'analisi e la classificazione delle immagini.\n",
        "3. Output:\n",
        "- Il sistema classificherà correttamente ogni immagine come veicolo o animale.\n",
        "\n",
        "## Valutazione del Modello:\n",
        "\n",
        "- **Accuratezza**: Proporzione di immagini classificate correttamente rispetto al totale.\n",
        "- **Precisione**: Qualità delle predizioni positive, indicando la proporzione di immagini correttamente identificate.\n",
        "\n",
        "## Analisi dei Risultati:\n",
        "\n",
        "- Identificazione di eventuali pattern di errore.\n",
        "- Valutazione delle categorie di immagini confuse sistematicamente.\n",
        "- Esame delle immagini errate e riflessione su possibili migliorie al modello.\n",
        "\n",
        "## Risultato Finale:\n",
        "\n",
        "- Presentazione completa della rete neurale convoluzionale e delle sue capacità di discriminazione tra veicoli e animali.\n",
        "- Discussione dettagliata delle metriche utilizzate e un'analisi critica delle prestazioni e limitazioni del modello.\n",
        "\n",
        "Questo progetto fornirà a VisionTech Solutions un sistema efficace per migliorare la sicurezza stradale e la gestione della fauna nelle aree urbane, dimostrando le competenze pratiche nell'applicazione del machine learning al riconoscimento delle immagini."
      ],
      "metadata": {
        "id": "Gb3Cd6ZyC09i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "W5wnXunXA9Gi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le classi di CIFAR-10 sono:\n",
        "* 0: aereo\n",
        "* 1: automobile\n",
        "* 2: uccello\n",
        "* 3: gatto\n",
        "* 4: cervo,\n",
        "* 5: cane\n",
        "* 6: rana\n",
        "* 7: cavallo\n",
        "* 8: nave\n",
        "* 9: camion\n",
        "    \n",
        "Mappiamo le classi originali a classi binarie:\n",
        "- Veicoli (0): aereo (0), automobile (1), nave (8), camion (9)\n",
        "- Animali (1): uccello (2), gatto (3), cervo (4), cane (5), rana (6), cavallo (7)"
      ],
      "metadata": {
        "id": "iyYCk38zBMTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_prepare_cifar10():\n",
        "    \"\"\"\n",
        "    Carica e prepara il dataset CIFAR-10, selezionando solo le classi di interesse:\n",
        "    - Veicoli: automobile, camion, nave, aereo\n",
        "    - Animali: uccello, gatto, cervo, cane, rana, cavallo\n",
        "    \"\"\"\n",
        "    print(\"Caricamento del dataset CIFAR-10...\")\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "    # Creazione della mappa delle classi\n",
        "    class_mapping = {\n",
        "        0: 0,  # aereo -> veicolo\n",
        "        1: 0,  # automobile -> veicolo\n",
        "        2: 1,  # uccello -> animale\n",
        "        3: 1,  # gatto -> animale\n",
        "        4: 1,  # cervo -> animale\n",
        "        5: 1,  # cane -> animale\n",
        "        6: 1,  # rana -> animale\n",
        "        7: 1,  # cavallo -> animale\n",
        "        8: 0,  # nave -> veicolo\n",
        "        9: 0   # camion -> veicolo\n",
        "    }\n",
        "\n",
        "    # Applicazione della mappatura\n",
        "    y_train_binary = np.array([class_mapping[y[0]] for y in y_train])\n",
        "    y_test_binary = np.array([class_mapping[y[0]] for y in y_test])\n",
        "\n",
        "    # Separazione degli indici di validazione dal set di addestramento\n",
        "    x_train, x_val, y_train_binary, y_val_binary = train_test_split(\n",
        "        x_train, y_train_binary, test_size=0.2, random_state=42, stratify=y_train_binary\n",
        "    )\n",
        "\n",
        "    # Normalizzazione dei dati (0-255 -> 0-1)\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_val = x_val.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "    # One-hot encoding per le etichette (anche se sono binarie)\n",
        "    y_train_binary = to_categorical(y_train_binary, 2)\n",
        "    y_val_binary = to_categorical(y_val_binary, 2)\n",
        "    y_test_binary = to_categorical(y_test_binary, 2)\n",
        "\n",
        "    class_names = ['Veicolo', 'Animale']\n",
        "\n",
        "    print(f\"Dati preparati. Forma dei dati:\")\n",
        "    print(f\"  Train: {x_train.shape} con {len(y_train_binary)} etichette\")\n",
        "    print(f\"  Validation: {x_val.shape} con {len(y_val_binary)} etichette\")\n",
        "    print(f\"  Test: {x_test.shape} con {len(y_test_binary)} etichette\")\n",
        "\n",
        "    return (x_train, y_train_binary), (x_val, y_val_binary), (x_test, y_test_binary), class_names\n",
        "\n",
        "load_and_prepare_cifar10()"
      ],
      "metadata": {
        "id": "7Ob3BPtKBErv",
        "outputId": "5cf976b2-9d7b-445a-a909-8e827adb25f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caricamento del dataset CIFAR-10...\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
            "Dati preparati. Forma dei dati:\n",
            "  Train: (40000, 32, 32, 3) con 40000 etichette\n",
            "  Validation: (10000, 32, 32, 3) con 10000 etichette\n",
            "  Test: (10000, 32, 32, 3) con 10000 etichette\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[[[0.09803922, 0.07843138, 0.10196079],\n",
              "           [0.09803922, 0.07843138, 0.10196079],\n",
              "           [0.09411765, 0.07450981, 0.09803922],\n",
              "           ...,\n",
              "           [0.07450981, 0.05882353, 0.0627451 ],\n",
              "           [0.07450981, 0.05882353, 0.07450981],\n",
              "           [0.07450981, 0.05490196, 0.07843138]],\n",
              "  \n",
              "          [[0.09411765, 0.07450981, 0.09803922],\n",
              "           [0.09411765, 0.07450981, 0.09803922],\n",
              "           [0.09411765, 0.07450981, 0.09803922],\n",
              "           ...,\n",
              "           [0.06666667, 0.05490196, 0.06666667],\n",
              "           [0.07058824, 0.05098039, 0.07450981],\n",
              "           [0.07058824, 0.05098039, 0.07450981]],\n",
              "  \n",
              "          [[0.09019608, 0.07058824, 0.09411765],\n",
              "           [0.09019608, 0.07058824, 0.09411765],\n",
              "           [0.09411765, 0.07450981, 0.09803922],\n",
              "           ...,\n",
              "           [0.0627451 , 0.05882353, 0.07450981],\n",
              "           [0.07058824, 0.05098039, 0.07450981],\n",
              "           [0.07058824, 0.05098039, 0.07450981]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[0.32156864, 0.19215687, 0.16470589],\n",
              "           [0.3647059 , 0.23137255, 0.20392157],\n",
              "           [0.47843137, 0.34901962, 0.31764707],\n",
              "           ...,\n",
              "           [0.24313726, 0.13725491, 0.12941177],\n",
              "           [0.25490198, 0.15686275, 0.13725491],\n",
              "           [0.25490198, 0.16078432, 0.13725491]],\n",
              "  \n",
              "          [[0.34509805, 0.20784314, 0.18431373],\n",
              "           [0.34509805, 0.20784314, 0.18431373],\n",
              "           [0.34901962, 0.20784314, 0.18431373],\n",
              "           ...,\n",
              "           [0.21960784, 0.1254902 , 0.10980392],\n",
              "           [0.23529412, 0.13725491, 0.11764706],\n",
              "           [0.23137255, 0.13333334, 0.11372549]],\n",
              "  \n",
              "          [[0.34509805, 0.19215687, 0.17254902],\n",
              "           [0.34117648, 0.1882353 , 0.16862746],\n",
              "           [0.3372549 , 0.18431373, 0.16470589],\n",
              "           ...,\n",
              "           [0.27450982, 0.16862746, 0.14901961],\n",
              "           [0.28235295, 0.17254902, 0.15686275],\n",
              "           [0.27450982, 0.16470589, 0.14901961]]],\n",
              "  \n",
              "  \n",
              "         [[[0.48235294, 0.42352942, 0.43529412],\n",
              "           [0.4862745 , 0.43137255, 0.43137255],\n",
              "           [0.5568628 , 0.5019608 , 0.49411765],\n",
              "           ...,\n",
              "           [0.54509807, 0.5254902 , 0.44313726],\n",
              "           [0.46666667, 0.4509804 , 0.36862746],\n",
              "           [0.43529412, 0.43529412, 0.3254902 ]],\n",
              "  \n",
              "          [[0.4862745 , 0.43137255, 0.4392157 ],\n",
              "           [0.49803922, 0.44313726, 0.4392157 ],\n",
              "           [0.5294118 , 0.4745098 , 0.46666667],\n",
              "           ...,\n",
              "           [0.59607846, 0.57254905, 0.49411765],\n",
              "           [0.5372549 , 0.5254902 , 0.45490196],\n",
              "           [0.46666667, 0.46666667, 0.4       ]],\n",
              "  \n",
              "          [[0.45882353, 0.40392157, 0.4117647 ],\n",
              "           [0.4745098 , 0.41960785, 0.41568628],\n",
              "           [0.5411765 , 0.4862745 , 0.47843137],\n",
              "           ...,\n",
              "           [0.6431373 , 0.61960787, 0.5411765 ],\n",
              "           [0.6       , 0.58431375, 0.5176471 ],\n",
              "           [0.5529412 , 0.54509807, 0.5019608 ]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[0.7294118 , 0.69803923, 0.63529414],\n",
              "           [0.7372549 , 0.7019608 , 0.654902  ],\n",
              "           [0.69803923, 0.6627451 , 0.61960787],\n",
              "           ...,\n",
              "           [0.5058824 , 0.46666667, 0.42352942],\n",
              "           [0.5294118 , 0.49411765, 0.45882353],\n",
              "           [0.5647059 , 0.5372549 , 0.5176471 ]],\n",
              "  \n",
              "          [[0.68235296, 0.64705884, 0.5803922 ],\n",
              "           [0.7019608 , 0.6666667 , 0.6117647 ],\n",
              "           [0.69803923, 0.65882355, 0.6117647 ],\n",
              "           ...,\n",
              "           [0.6313726 , 0.5882353 , 0.56078434],\n",
              "           [0.59607846, 0.5568628 , 0.53333336],\n",
              "           [0.6431373 , 0.60784316, 0.5921569 ]],\n",
              "  \n",
              "          [[0.6666667 , 0.63529414, 0.56078434],\n",
              "           [0.69803923, 0.6627451 , 0.6039216 ],\n",
              "           [0.7254902 , 0.6862745 , 0.63529414],\n",
              "           ...,\n",
              "           [0.7058824 , 0.6666667 , 0.6313726 ],\n",
              "           [0.6745098 , 0.63529414, 0.6       ],\n",
              "           [0.6392157 , 0.59607846, 0.5647059 ]]],\n",
              "  \n",
              "  \n",
              "         [[[0.62352943, 0.73333335, 0.78039217],\n",
              "           [0.6       , 0.7176471 , 0.7254902 ],\n",
              "           [0.5921569 , 0.70980394, 0.7176471 ],\n",
              "           ...,\n",
              "           [0.6156863 , 0.70980394, 0.7647059 ],\n",
              "           [0.61960787, 0.7137255 , 0.77254903],\n",
              "           [0.627451  , 0.7254902 , 0.78039217]],\n",
              "  \n",
              "          [[0.61960787, 0.73333335, 0.77254903],\n",
              "           [0.6       , 0.72156864, 0.7490196 ],\n",
              "           [0.59607846, 0.7137255 , 0.7411765 ],\n",
              "           ...,\n",
              "           [0.60784316, 0.7176471 , 0.7647059 ],\n",
              "           [0.60784316, 0.7176471 , 0.7764706 ],\n",
              "           [0.627451  , 0.7294118 , 0.7882353 ]],\n",
              "  \n",
              "          [[0.62352943, 0.7411765 , 0.78039217],\n",
              "           [0.6       , 0.7254902 , 0.7647059 ],\n",
              "           [0.59607846, 0.7176471 , 0.75686276],\n",
              "           ...,\n",
              "           [0.6313726 , 0.7294118 , 0.77254903],\n",
              "           [0.64705884, 0.73333335, 0.78039217],\n",
              "           [0.6313726 , 0.7019608 , 0.74509805]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[0.8039216 , 0.76862746, 0.7176471 ],\n",
              "           [0.7019608 , 0.6627451 , 0.6156863 ],\n",
              "           [0.68235296, 0.6392157 , 0.5882353 ],\n",
              "           ...,\n",
              "           [0.8901961 , 0.83137256, 0.7490196 ],\n",
              "           [0.88235295, 0.81960785, 0.73333335],\n",
              "           [0.8745098 , 0.8117647 , 0.7254902 ]],\n",
              "  \n",
              "          [[0.93333334, 0.89411765, 0.827451  ],\n",
              "           [0.94509804, 0.8901961 , 0.83137256],\n",
              "           [0.94509804, 0.89411765, 0.827451  ],\n",
              "           ...,\n",
              "           [0.8784314 , 0.8235294 , 0.74509805],\n",
              "           [0.8666667 , 0.8117647 , 0.73333335],\n",
              "           [0.84705883, 0.8       , 0.7254902 ]],\n",
              "  \n",
              "          [[0.85490197, 0.80784315, 0.7607843 ],\n",
              "           [0.84313726, 0.78431374, 0.7411765 ],\n",
              "           [0.8509804 , 0.79607844, 0.7490196 ],\n",
              "           ...,\n",
              "           [0.83137256, 0.7882353 , 0.7176471 ],\n",
              "           [0.827451  , 0.78431374, 0.7176471 ],\n",
              "           [0.8235294 , 0.7882353 , 0.7254902 ]]],\n",
              "  \n",
              "  \n",
              "         ...,\n",
              "  \n",
              "  \n",
              "         [[[0.22745098, 0.39607844, 0.4745098 ],\n",
              "           [0.21960784, 0.3882353 , 0.45490196],\n",
              "           [0.22352941, 0.38431373, 0.44313726],\n",
              "           ...,\n",
              "           [0.2509804 , 0.47058824, 0.5803922 ],\n",
              "           [0.23921569, 0.45882353, 0.5803922 ],\n",
              "           [0.22745098, 0.44705883, 0.5686275 ]],\n",
              "  \n",
              "          [[0.2509804 , 0.44313726, 0.5411765 ],\n",
              "           [0.24705882, 0.43137255, 0.5058824 ],\n",
              "           [0.24705882, 0.41960785, 0.47843137],\n",
              "           ...,\n",
              "           [0.26666668, 0.4862745 , 0.6156863 ],\n",
              "           [0.25882354, 0.48235294, 0.60784316],\n",
              "           [0.24313726, 0.46666667, 0.5882353 ]],\n",
              "  \n",
              "          [[0.27058825, 0.46666667, 0.5568628 ],\n",
              "           [0.2784314 , 0.47843137, 0.5686275 ],\n",
              "           [0.28235295, 0.4745098 , 0.5647059 ],\n",
              "           ...,\n",
              "           [0.2901961 , 0.50980395, 0.6392157 ],\n",
              "           [0.28235295, 0.5019608 , 0.6313726 ],\n",
              "           [0.26666668, 0.48235294, 0.6117647 ]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[0.5647059 , 0.65882355, 0.7764706 ],\n",
              "           [0.5882353 , 0.6862745 , 0.8039216 ],\n",
              "           [0.6       , 0.69411767, 0.8117647 ],\n",
              "           ...,\n",
              "           [0.15686275, 0.16470589, 0.12156863],\n",
              "           [0.16862746, 0.1764706 , 0.13333334],\n",
              "           [0.18039216, 0.1882353 , 0.14509805]],\n",
              "  \n",
              "          [[0.5921569 , 0.6901961 , 0.8039216 ],\n",
              "           [0.60784316, 0.7058824 , 0.8235294 ],\n",
              "           [0.60784316, 0.7058824 , 0.8235294 ],\n",
              "           ...,\n",
              "           [0.12156863, 0.12941177, 0.08235294],\n",
              "           [0.1254902 , 0.13333334, 0.08627451],\n",
              "           [0.13333334, 0.13725491, 0.09411765]],\n",
              "  \n",
              "          [[0.5372549 , 0.6431373 , 0.75686276],\n",
              "           [0.5529412 , 0.65882355, 0.77254903],\n",
              "           [0.54901963, 0.6509804 , 0.77254903],\n",
              "           ...,\n",
              "           [0.14509805, 0.15294118, 0.10196079],\n",
              "           [0.16078432, 0.16078432, 0.11372549],\n",
              "           [0.17254902, 0.17254902, 0.12941177]]],\n",
              "  \n",
              "  \n",
              "         [[[0.09019608, 0.01960784, 0.01176471],\n",
              "           [0.09019608, 0.01960784, 0.01176471],\n",
              "           [0.09019608, 0.01960784, 0.00392157],\n",
              "           ...,\n",
              "           [0.08627451, 0.03529412, 0.00784314],\n",
              "           [0.09803922, 0.02745098, 0.01568628],\n",
              "           [0.09803922, 0.02745098, 0.01568628]],\n",
              "  \n",
              "          [[0.09019608, 0.01960784, 0.01176471],\n",
              "           [0.09019608, 0.01960784, 0.01176471],\n",
              "           [0.09019608, 0.01960784, 0.00392157],\n",
              "           ...,\n",
              "           [0.09019608, 0.03921569, 0.00784314],\n",
              "           [0.10588235, 0.03921569, 0.01176471],\n",
              "           [0.10196079, 0.03529412, 0.00784314]],\n",
              "  \n",
              "          [[0.09019608, 0.01960784, 0.01176471],\n",
              "           [0.09019608, 0.01960784, 0.01176471],\n",
              "           [0.09019608, 0.01960784, 0.00392157],\n",
              "           ...,\n",
              "           [0.09019608, 0.04313726, 0.00784314],\n",
              "           [0.10588235, 0.03921569, 0.00392157],\n",
              "           [0.10588235, 0.03921569, 0.        ]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[0.6901961 , 0.67058825, 0.45490196],\n",
              "           [0.6666667 , 0.6627451 , 0.4392157 ],\n",
              "           [0.5372549 , 0.54901963, 0.3137255 ],\n",
              "           ...,\n",
              "           [0.99215686, 0.9647059 , 0.8784314 ],\n",
              "           [0.9411765 , 0.91764706, 0.81960785],\n",
              "           [0.9019608 , 0.90588236, 0.7607843 ]],\n",
              "  \n",
              "          [[0.627451  , 0.6117647 , 0.42352942],\n",
              "           [0.6392157 , 0.627451  , 0.40392157],\n",
              "           [0.6313726 , 0.6392157 , 0.40784314],\n",
              "           ...,\n",
              "           [0.9098039 , 0.9254902 , 0.69803923],\n",
              "           [0.83137256, 0.84313726, 0.627451  ],\n",
              "           [0.7372549 , 0.75686276, 0.5254902 ]],\n",
              "  \n",
              "          [[0.6313726 , 0.6156863 , 0.43529412],\n",
              "           [0.5882353 , 0.5803922 , 0.35686275],\n",
              "           [0.5921569 , 0.6039216 , 0.3529412 ],\n",
              "           ...,\n",
              "           [0.7372549 , 0.77254903, 0.45490196],\n",
              "           [0.70980394, 0.7411765 , 0.4509804 ],\n",
              "           [0.67058825, 0.7019608 , 0.4117647 ]]],\n",
              "  \n",
              "  \n",
              "         [[[1.        , 1.        , 1.        ],\n",
              "           [0.99215686, 0.9882353 , 0.99607843],\n",
              "           [0.94509804, 0.9490196 , 0.9411765 ],\n",
              "           ...,\n",
              "           [1.        , 1.        , 1.        ],\n",
              "           [1.        , 1.        , 1.        ],\n",
              "           [1.        , 1.        , 1.        ]],\n",
              "  \n",
              "          [[1.        , 1.        , 1.        ],\n",
              "           [0.99607843, 0.99215686, 1.        ],\n",
              "           [0.83137256, 0.83137256, 0.8235294 ],\n",
              "           ...,\n",
              "           [1.        , 1.        , 1.        ],\n",
              "           [1.        , 1.        , 1.        ],\n",
              "           [1.        , 1.        , 1.        ]],\n",
              "  \n",
              "          [[1.        , 1.        , 1.        ],\n",
              "           [0.99607843, 0.99607843, 1.        ],\n",
              "           [0.91764706, 0.92156863, 0.9098039 ],\n",
              "           ...,\n",
              "           [1.        , 1.        , 1.        ],\n",
              "           [1.        , 1.        , 1.        ],\n",
              "           [1.        , 1.        , 1.        ]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[0.99607843, 0.99607843, 0.99215686],\n",
              "           [0.9254902 , 0.92941177, 0.90588236],\n",
              "           [0.5803922 , 0.5647059 , 0.5411765 ],\n",
              "           ...,\n",
              "           [0.13333334, 0.05882353, 0.03529412],\n",
              "           [0.7176471 , 0.7019608 , 0.6784314 ],\n",
              "           [1.        , 1.        , 1.        ]],\n",
              "  \n",
              "          [[0.99607843, 1.        , 1.        ],\n",
              "           [0.9607843 , 0.972549  , 0.9607843 ],\n",
              "           [0.6627451 , 0.65882355, 0.64705884],\n",
              "           ...,\n",
              "           [0.22352941, 0.14901961, 0.13333334],\n",
              "           [0.90588236, 0.8862745 , 0.8862745 ],\n",
              "           [0.99607843, 0.99607843, 0.99607843]],\n",
              "  \n",
              "          [[1.        , 1.        , 1.        ],\n",
              "           [0.9843137 , 0.99215686, 0.9882353 ],\n",
              "           [0.9882353 , 0.9882353 , 0.9843137 ],\n",
              "           ...,\n",
              "           [0.28627452, 0.22745098, 0.22745098],\n",
              "           [0.74509805, 0.7254902 , 0.7294118 ],\n",
              "           [0.9490196 , 0.9490196 , 0.9490196 ]]]], dtype=float32),\n",
              "  array([[0., 1.],\n",
              "         [0., 1.],\n",
              "         [1., 0.],\n",
              "         ...,\n",
              "         [0., 1.],\n",
              "         [0., 1.],\n",
              "         [1., 0.]])),\n",
              " (array([[[[0.58431375, 0.6313726 , 0.60784316],\n",
              "           [0.6627451 , 0.69803923, 0.68235296],\n",
              "           [0.9098039 , 0.9098039 , 0.9019608 ],\n",
              "           ...,\n",
              "           [0.9647059 , 0.9529412 , 0.9764706 ],\n",
              "           [0.9411765 , 0.92941177, 0.9411765 ],\n",
              "           [0.93333334, 0.92941177, 0.92156863]],\n",
              "  \n",
              "          [[0.22352941, 0.28627452, 0.2509804 ],\n",
              "           [0.2901961 , 0.35686275, 0.31764707],\n",
              "           [0.6431373 , 0.6862745 , 0.65882355],\n",
              "           ...,\n",
              "           [0.95686275, 0.9529412 , 0.972549  ],\n",
              "           [0.9254902 , 0.92941177, 0.93333334],\n",
              "           [0.9254902 , 0.92941177, 0.92156863]],\n",
              "  \n",
              "          [[0.34509805, 0.41960785, 0.37254903],\n",
              "           [0.13333334, 0.21568628, 0.16078432],\n",
              "           [0.34901962, 0.43137255, 0.3882353 ],\n",
              "           ...,\n",
              "           [0.93333334, 0.9411765 , 0.9490196 ],\n",
              "           [0.89411765, 0.9254902 , 0.91764706],\n",
              "           [0.8980392 , 0.91764706, 0.9098039 ]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[0.26666668, 0.25490198, 0.20392157],\n",
              "           [0.31764707, 0.2901961 , 0.24313726],\n",
              "           [0.30980393, 0.2784314 , 0.23921569],\n",
              "           ...,\n",
              "           [0.3529412 , 0.18431373, 0.16078432],\n",
              "           [0.34509805, 0.19215687, 0.16470589],\n",
              "           [0.14901961, 0.07450981, 0.07843138]],\n",
              "  \n",
              "          [[0.25882354, 0.24313726, 0.19607843],\n",
              "           [0.28235295, 0.24313726, 0.20784314],\n",
              "           [0.27450982, 0.21568628, 0.1882353 ],\n",
              "           ...,\n",
              "           [0.38431373, 0.1882353 , 0.16078432],\n",
              "           [0.36078432, 0.17254902, 0.14901961],\n",
              "           [0.23137255, 0.10980392, 0.10588235]],\n",
              "  \n",
              "          [[0.2784314 , 0.23921569, 0.20392157],\n",
              "           [0.28235295, 0.21960784, 0.19215687],\n",
              "           [0.27058825, 0.1882353 , 0.16862746],\n",
              "           ...,\n",
              "           [0.41568628, 0.2       , 0.17254902],\n",
              "           [0.39607844, 0.18431373, 0.16470589],\n",
              "           [0.32156864, 0.16862746, 0.17254902]]],\n",
              "  \n",
              "  \n",
              "         [[[0.43137255, 0.53333336, 0.5529412 ],\n",
              "           [0.41568628, 0.5294118 , 0.5568628 ],\n",
              "           [0.42745098, 0.5254902 , 0.5411765 ],\n",
              "           ...,\n",
              "           [0.36862746, 0.4509804 , 0.46666667],\n",
              "           [0.40784314, 0.49411765, 0.49019608],\n",
              "           [0.40392157, 0.4862745 , 0.49019608]],\n",
              "  \n",
              "          [[0.39215687, 0.49803922, 0.50980395],\n",
              "           [0.4       , 0.49803922, 0.5294118 ],\n",
              "           [0.39607844, 0.48235294, 0.52156866],\n",
              "           ...,\n",
              "           [0.3764706 , 0.45882353, 0.47058824],\n",
              "           [0.4       , 0.48235294, 0.4745098 ],\n",
              "           [0.39607844, 0.46666667, 0.46666667]],\n",
              "  \n",
              "          [[0.36862746, 0.45882353, 0.4745098 ],\n",
              "           [0.41568628, 0.4862745 , 0.49803922],\n",
              "           [0.39607844, 0.45882353, 0.48235294],\n",
              "           ...,\n",
              "           [0.39215687, 0.4745098 , 0.47843137],\n",
              "           [0.42745098, 0.5176471 , 0.49803922],\n",
              "           [0.42745098, 0.5137255 , 0.49411765]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[0.5568628 , 0.64705884, 0.3019608 ],\n",
              "           [0.54901963, 0.63529414, 0.29411766],\n",
              "           [0.5411765 , 0.6313726 , 0.2784314 ],\n",
              "           ...,\n",
              "           [0.50980395, 0.5921569 , 0.28627452],\n",
              "           [0.5058824 , 0.59607846, 0.26666668],\n",
              "           [0.5568628 , 0.654902  , 0.29803923]],\n",
              "  \n",
              "          [[0.53333336, 0.627451  , 0.28627452],\n",
              "           [0.5176471 , 0.6117647 , 0.26666668],\n",
              "           [0.52156866, 0.61960787, 0.26666668],\n",
              "           ...,\n",
              "           [0.50980395, 0.58431375, 0.3254902 ],\n",
              "           [0.5019608 , 0.58431375, 0.30588236],\n",
              "           [0.5372549 , 0.627451  , 0.3372549 ]],\n",
              "  \n",
              "          [[0.50980395, 0.60784316, 0.2627451 ],\n",
              "           [0.49019608, 0.58431375, 0.23137255],\n",
              "           [0.5019608 , 0.6       , 0.24705882],\n",
              "           ...,\n",
              "           [0.3764706 , 0.4509804 , 0.20784314],\n",
              "           [0.39607844, 0.47058824, 0.23137255],\n",
              "           [0.40392157, 0.49411765, 0.23529412]]],\n",
              "  \n",
              "  \n",
              "         [[[0.16078432, 0.30980393, 0.5411765 ],\n",
              "           [0.19215687, 0.35686275, 0.6039216 ],\n",
              "           [0.21960784, 0.4       , 0.65882355],\n",
              "           ...,\n",
              "           [0.5647059 , 0.62352943, 0.6509804 ],\n",
              "           [0.56078434, 0.627451  , 0.6509804 ],\n",
              "           [0.5568628 , 0.6313726 , 0.654902  ]],\n",
              "  \n",
              "          [[0.1764706 , 0.31764707, 0.5647059 ],\n",
              "           [0.22745098, 0.36862746, 0.6117647 ],\n",
              "           [0.18039216, 0.32941177, 0.5764706 ],\n",
              "           ...,\n",
              "           [0.60784316, 0.6509804 , 0.6862745 ],\n",
              "           [0.6039216 , 0.6509804 , 0.68235296],\n",
              "           [0.59607846, 0.6509804 , 0.6784314 ]],\n",
              "  \n",
              "          [[0.19607843, 0.3372549 , 0.5803922 ],\n",
              "           [0.1882353 , 0.32941177, 0.5647059 ],\n",
              "           [0.1882353 , 0.32941177, 0.5647059 ],\n",
              "           ...,\n",
              "           [0.63529414, 0.6745098 , 0.70980394],\n",
              "           [0.61960787, 0.6627451 , 0.69411767],\n",
              "           [0.5882353 , 0.6392157 , 0.67058825]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[0.7137255 , 0.7137255 , 0.67058825],\n",
              "           [0.7058824 , 0.69411767, 0.65882355],\n",
              "           [0.72156864, 0.7058824 , 0.6666667 ],\n",
              "           ...,\n",
              "           [0.8509804 , 0.8235294 , 0.80784315],\n",
              "           [0.84705883, 0.827451  , 0.8       ],\n",
              "           [0.80784315, 0.79607844, 0.78431374]],\n",
              "  \n",
              "          [[0.70980394, 0.7137255 , 0.67058825],\n",
              "           [0.70980394, 0.7058824 , 0.67058825],\n",
              "           [0.72156864, 0.7058824 , 0.6745098 ],\n",
              "           ...,\n",
              "           [0.84705883, 0.827451  , 0.8039216 ],\n",
              "           [0.84313726, 0.83137256, 0.8       ],\n",
              "           [0.8117647 , 0.8039216 , 0.79607844]],\n",
              "  \n",
              "          [[0.7254902 , 0.7294118 , 0.69411767],\n",
              "           [0.7294118 , 0.7294118 , 0.69803923],\n",
              "           [0.7411765 , 0.73333335, 0.7019608 ],\n",
              "           ...,\n",
              "           [0.8666667 , 0.8509804 , 0.81960785],\n",
              "           [0.84705883, 0.8392157 , 0.80784315],\n",
              "           [0.81960785, 0.8156863 , 0.8117647 ]]],\n",
              "  \n",
              "  \n",
              "         ...,\n",
              "  \n",
              "  \n",
              "         [[[0.37254903, 0.4862745 , 0.41568628],\n",
              "           [0.33333334, 0.43529412, 0.34509805],\n",
              "           [0.25490198, 0.33333334, 0.24313726],\n",
              "           ...,\n",
              "           [0.31764707, 0.40392157, 0.25490198],\n",
              "           [0.2784314 , 0.33333334, 0.21568628],\n",
              "           [0.3529412 , 0.45490196, 0.31764707]],\n",
              "  \n",
              "          [[0.34117648, 0.44313726, 0.37254903],\n",
              "           [0.22745098, 0.3137255 , 0.22352941],\n",
              "           [0.2       , 0.27058825, 0.16470589],\n",
              "           ...,\n",
              "           [0.2901961 , 0.3882353 , 0.23529412],\n",
              "           [0.2901961 , 0.34117648, 0.22745098],\n",
              "           [0.30588236, 0.3764706 , 0.2627451 ]],\n",
              "  \n",
              "          [[0.3254902 , 0.4392157 , 0.3372549 ],\n",
              "           [0.21960784, 0.30588236, 0.20784314],\n",
              "           [0.20784314, 0.26666668, 0.18431373],\n",
              "           ...,\n",
              "           [0.29803923, 0.42745098, 0.27058825],\n",
              "           [0.31764707, 0.36862746, 0.24705882],\n",
              "           [0.27450982, 0.3019608 , 0.20392157]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[0.6156863 , 0.68235296, 0.52156866],\n",
              "           [0.5137255 , 0.57254905, 0.4       ],\n",
              "           [0.4392157 , 0.46666667, 0.31764707],\n",
              "           ...,\n",
              "           [0.5294118 , 0.60784316, 0.47843137],\n",
              "           [0.5176471 , 0.60784316, 0.39607844],\n",
              "           [0.42352942, 0.49803922, 0.27058825]],\n",
              "  \n",
              "          [[0.6117647 , 0.69803923, 0.5294118 ],\n",
              "           [0.5529412 , 0.6392157 , 0.4509804 ],\n",
              "           [0.4392157 , 0.5137255 , 0.34901962],\n",
              "           ...,\n",
              "           [0.45882353, 0.57254905, 0.4       ],\n",
              "           [0.4509804 , 0.56078434, 0.3529412 ],\n",
              "           [0.4117647 , 0.5137255 , 0.2784314 ]],\n",
              "  \n",
              "          [[0.5803922 , 0.6784314 , 0.5058824 ],\n",
              "           [0.5254902 , 0.6156863 , 0.4392157 ],\n",
              "           [0.4745098 , 0.5764706 , 0.41568628],\n",
              "           ...,\n",
              "           [0.3764706 , 0.48235294, 0.28627452],\n",
              "           [0.3372549 , 0.44705883, 0.24705882],\n",
              "           [0.31764707, 0.43529412, 0.19607843]]],\n",
              "  \n",
              "  \n",
              "         [[[0.60784316, 0.74509805, 0.84705883],\n",
              "           [0.6       , 0.7372549 , 0.8352941 ],\n",
              "           [0.60784316, 0.7411765 , 0.84313726],\n",
              "           ...,\n",
              "           [0.61960787, 0.7882353 , 0.88235295],\n",
              "           [0.6156863 , 0.78039217, 0.8784314 ],\n",
              "           [0.61960787, 0.7882353 , 0.8862745 ]],\n",
              "  \n",
              "          [[0.6039216 , 0.7411765 , 0.8392157 ],\n",
              "           [0.6       , 0.7294118 , 0.827451  ],\n",
              "           [0.6039216 , 0.7372549 , 0.8352941 ],\n",
              "           ...,\n",
              "           [0.6156863 , 0.78039217, 0.8745098 ],\n",
              "           [0.6117647 , 0.7764706 , 0.87058824],\n",
              "           [0.61960787, 0.78431374, 0.88235295]],\n",
              "  \n",
              "          [[0.6039216 , 0.7411765 , 0.8392157 ],\n",
              "           [0.6       , 0.73333335, 0.83137256],\n",
              "           [0.6039216 , 0.7372549 , 0.8352941 ],\n",
              "           ...,\n",
              "           [0.61960787, 0.78431374, 0.8784314 ],\n",
              "           [0.6156863 , 0.78039217, 0.8745098 ],\n",
              "           [0.62352943, 0.7921569 , 0.8901961 ]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[0.58431375, 0.48235294, 0.3764706 ],\n",
              "           [0.5647059 , 0.46666667, 0.36862746],\n",
              "           [0.56078434, 0.46666667, 0.37254903],\n",
              "           ...,\n",
              "           [0.61960787, 0.56078434, 0.46666667],\n",
              "           [0.5921569 , 0.53333336, 0.4392157 ],\n",
              "           [0.60784316, 0.54901963, 0.45490196]],\n",
              "  \n",
              "          [[0.58431375, 0.48235294, 0.35686275],\n",
              "           [0.59607846, 0.49803922, 0.37254903],\n",
              "           [0.5882353 , 0.49019608, 0.36078432],\n",
              "           ...,\n",
              "           [0.6313726 , 0.5568628 , 0.44705883],\n",
              "           [0.5882353 , 0.50980395, 0.40392157],\n",
              "           [0.627451  , 0.54901963, 0.44313726]],\n",
              "  \n",
              "          [[0.5686275 , 0.44705883, 0.2901961 ],\n",
              "           [0.59607846, 0.47843137, 0.3254902 ],\n",
              "           [0.6039216 , 0.48235294, 0.32941177],\n",
              "           ...,\n",
              "           [0.54901963, 0.45490196, 0.3254902 ],\n",
              "           [0.5803922 , 0.4862745 , 0.35686275],\n",
              "           [0.6       , 0.5058824 , 0.3764706 ]]],\n",
              "  \n",
              "  \n",
              "         [[[0.8156863 , 0.8862745 , 0.9529412 ],\n",
              "           [0.8       , 0.8666667 , 0.93333334],\n",
              "           [0.79607844, 0.8627451 , 0.92941177],\n",
              "           ...,\n",
              "           [0.6       , 0.6627451 , 0.7254902 ],\n",
              "           [0.6       , 0.6627451 , 0.7254902 ],\n",
              "           [0.60784316, 0.67058825, 0.7372549 ]],\n",
              "  \n",
              "          [[0.81960785, 0.8901961 , 0.9490196 ],\n",
              "           [0.8       , 0.87058824, 0.9254902 ],\n",
              "           [0.79607844, 0.8666667 , 0.92156863],\n",
              "           ...,\n",
              "           [0.6       , 0.6627451 , 0.72156864],\n",
              "           [0.6       , 0.6627451 , 0.72156864],\n",
              "           [0.60784316, 0.67058825, 0.7294118 ]],\n",
              "  \n",
              "          [[0.8392157 , 0.9098039 , 0.95686275],\n",
              "           [0.81960785, 0.8901961 , 0.9372549 ],\n",
              "           [0.8117647 , 0.88235295, 0.92941177],\n",
              "           ...,\n",
              "           [0.6156863 , 0.6784314 , 0.7372549 ],\n",
              "           [0.61960787, 0.68235296, 0.7372549 ],\n",
              "           [0.62352943, 0.6862745 , 0.7372549 ]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[0.76862746, 0.7372549 , 0.7607843 ],\n",
              "           [0.7411765 , 0.7137255 , 0.73333335],\n",
              "           [0.73333335, 0.7019608 , 0.7254902 ],\n",
              "           ...,\n",
              "           [0.5058824 , 0.47058824, 0.47058824],\n",
              "           [0.50980395, 0.4745098 , 0.4745098 ],\n",
              "           [0.5254902 , 0.4862745 , 0.49019608]],\n",
              "  \n",
              "          [[0.80784315, 0.7607843 , 0.76862746],\n",
              "           [0.7882353 , 0.7411765 , 0.7490196 ],\n",
              "           [0.7764706 , 0.7294118 , 0.7372549 ],\n",
              "           ...,\n",
              "           [0.49019608, 0.4509804 , 0.44313726],\n",
              "           [0.5019608 , 0.4627451 , 0.45882353],\n",
              "           [0.5294118 , 0.49019608, 0.49411765]],\n",
              "  \n",
              "          [[0.8509804 , 0.78431374, 0.78431374],\n",
              "           [0.8352941 , 0.77254903, 0.77254903],\n",
              "           [0.8235294 , 0.7607843 , 0.7607843 ],\n",
              "           ...,\n",
              "           [0.5686275 , 0.5137255 , 0.5019608 ],\n",
              "           [0.56078434, 0.5176471 , 0.50980395],\n",
              "           [0.5411765 , 0.5019608 , 0.5058824 ]]]], dtype=float32),\n",
              "  array([[1., 0.],\n",
              "         [0., 1.],\n",
              "         [0., 1.],\n",
              "         ...,\n",
              "         [0., 1.],\n",
              "         [0., 1.],\n",
              "         [1., 0.]])),\n",
              " (array([[[[0.61960787, 0.4392157 , 0.19215687],\n",
              "           [0.62352943, 0.43529412, 0.18431373],\n",
              "           [0.64705884, 0.45490196, 0.2       ],\n",
              "           ...,\n",
              "           [0.5372549 , 0.37254903, 0.14117648],\n",
              "           [0.49411765, 0.35686275, 0.14117648],\n",
              "           [0.45490196, 0.33333334, 0.12941177]],\n",
              "  \n",
              "          [[0.59607846, 0.4392157 , 0.2       ],\n",
              "           [0.5921569 , 0.43137255, 0.15686275],\n",
              "           [0.62352943, 0.44705883, 0.1764706 ],\n",
              "           ...,\n",
              "           [0.53333336, 0.37254903, 0.12156863],\n",
              "           [0.49019608, 0.35686275, 0.1254902 ],\n",
              "           [0.46666667, 0.34509805, 0.13333334]],\n",
              "  \n",
              "          [[0.5921569 , 0.43137255, 0.18431373],\n",
              "           [0.5921569 , 0.42745098, 0.12941177],\n",
              "           [0.61960787, 0.43529412, 0.14117648],\n",
              "           ...,\n",
              "           [0.54509807, 0.38431373, 0.13333334],\n",
              "           [0.50980395, 0.37254903, 0.13333334],\n",
              "           [0.47058824, 0.34901962, 0.12941177]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[0.26666668, 0.4862745 , 0.69411767],\n",
              "           [0.16470589, 0.39215687, 0.5803922 ],\n",
              "           [0.12156863, 0.34509805, 0.5372549 ],\n",
              "           ...,\n",
              "           [0.14901961, 0.38039216, 0.57254905],\n",
              "           [0.05098039, 0.2509804 , 0.42352942],\n",
              "           [0.15686275, 0.33333334, 0.49803922]],\n",
              "  \n",
              "          [[0.23921569, 0.45490196, 0.65882355],\n",
              "           [0.19215687, 0.4       , 0.5803922 ],\n",
              "           [0.13725491, 0.33333334, 0.5176471 ],\n",
              "           ...,\n",
              "           [0.10196079, 0.32156864, 0.50980395],\n",
              "           [0.11372549, 0.32156864, 0.49411765],\n",
              "           [0.07843138, 0.2509804 , 0.41960785]],\n",
              "  \n",
              "          [[0.21176471, 0.41960785, 0.627451  ],\n",
              "           [0.21960784, 0.4117647 , 0.58431375],\n",
              "           [0.1764706 , 0.34901962, 0.5176471 ],\n",
              "           ...,\n",
              "           [0.09411765, 0.3019608 , 0.4862745 ],\n",
              "           [0.13333334, 0.32941177, 0.5058824 ],\n",
              "           [0.08235294, 0.2627451 , 0.43137255]]],\n",
              "  \n",
              "  \n",
              "         [[[0.92156863, 0.92156863, 0.92156863],\n",
              "           [0.90588236, 0.90588236, 0.90588236],\n",
              "           [0.9098039 , 0.9098039 , 0.9098039 ],\n",
              "           ...,\n",
              "           [0.9137255 , 0.9137255 , 0.9137255 ],\n",
              "           [0.9137255 , 0.9137255 , 0.9137255 ],\n",
              "           [0.9098039 , 0.9098039 , 0.9098039 ]],\n",
              "  \n",
              "          [[0.93333334, 0.93333334, 0.93333334],\n",
              "           [0.92156863, 0.92156863, 0.92156863],\n",
              "           [0.92156863, 0.92156863, 0.92156863],\n",
              "           ...,\n",
              "           [0.9254902 , 0.9254902 , 0.9254902 ],\n",
              "           [0.9254902 , 0.9254902 , 0.9254902 ],\n",
              "           [0.92156863, 0.92156863, 0.92156863]],\n",
              "  \n",
              "          [[0.92941177, 0.92941177, 0.92941177],\n",
              "           [0.91764706, 0.91764706, 0.91764706],\n",
              "           [0.91764706, 0.91764706, 0.91764706],\n",
              "           ...,\n",
              "           [0.92156863, 0.92156863, 0.92156863],\n",
              "           [0.92156863, 0.92156863, 0.92156863],\n",
              "           [0.91764706, 0.91764706, 0.91764706]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[0.34117648, 0.3882353 , 0.34901962],\n",
              "           [0.16862746, 0.2       , 0.14509805],\n",
              "           [0.07450981, 0.09019608, 0.04313726],\n",
              "           ...,\n",
              "           [0.6627451 , 0.72156864, 0.7019608 ],\n",
              "           [0.7137255 , 0.77254903, 0.75686276],\n",
              "           [0.7372549 , 0.7921569 , 0.7882353 ]],\n",
              "  \n",
              "          [[0.32156864, 0.3764706 , 0.32156864],\n",
              "           [0.18039216, 0.22352941, 0.14117648],\n",
              "           [0.14117648, 0.17254902, 0.08627451],\n",
              "           ...,\n",
              "           [0.68235296, 0.7411765 , 0.7176471 ],\n",
              "           [0.7254902 , 0.78431374, 0.76862746],\n",
              "           [0.73333335, 0.7921569 , 0.78431374]],\n",
              "  \n",
              "          [[0.33333334, 0.39607844, 0.3254902 ],\n",
              "           [0.24313726, 0.29411766, 0.1882353 ],\n",
              "           [0.22745098, 0.2627451 , 0.14901961],\n",
              "           ...,\n",
              "           [0.65882355, 0.7176471 , 0.69803923],\n",
              "           [0.7058824 , 0.7647059 , 0.7490196 ],\n",
              "           [0.7294118 , 0.78431374, 0.78039217]]],\n",
              "  \n",
              "  \n",
              "         [[[0.61960787, 0.74509805, 0.87058824],\n",
              "           [0.61960787, 0.73333335, 0.85490197],\n",
              "           [0.54509807, 0.6509804 , 0.7607843 ],\n",
              "           ...,\n",
              "           [0.89411765, 0.90588236, 0.91764706],\n",
              "           [0.92941177, 0.9372549 , 0.9529412 ],\n",
              "           [0.93333334, 0.94509804, 0.9647059 ]],\n",
              "  \n",
              "          [[0.6666667 , 0.78431374, 0.8980392 ],\n",
              "           [0.6745098 , 0.78039217, 0.8862745 ],\n",
              "           [0.5921569 , 0.6901961 , 0.7882353 ],\n",
              "           ...,\n",
              "           [0.9098039 , 0.9098039 , 0.9254902 ],\n",
              "           [0.9647059 , 0.9647059 , 0.98039216],\n",
              "           [0.9647059 , 0.96862745, 0.9843137 ]],\n",
              "  \n",
              "          [[0.68235296, 0.7882353 , 0.88235295],\n",
              "           [0.6901961 , 0.78431374, 0.87058824],\n",
              "           [0.6156863 , 0.7019608 , 0.78039217],\n",
              "           ...,\n",
              "           [0.9019608 , 0.8980392 , 0.9098039 ],\n",
              "           [0.98039216, 0.9764706 , 0.9843137 ],\n",
              "           [0.9607843 , 0.95686275, 0.96862745]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[0.12156863, 0.15686275, 0.1764706 ],\n",
              "           [0.11764706, 0.15294118, 0.17254902],\n",
              "           [0.10196079, 0.13725491, 0.15686275],\n",
              "           ...,\n",
              "           [0.14509805, 0.15686275, 0.18039216],\n",
              "           [0.03529412, 0.05098039, 0.05490196],\n",
              "           [0.01568628, 0.02745098, 0.01960784]],\n",
              "  \n",
              "          [[0.09019608, 0.13333334, 0.15294118],\n",
              "           [0.10588235, 0.14901961, 0.16862746],\n",
              "           [0.09803922, 0.14117648, 0.16078432],\n",
              "           ...,\n",
              "           [0.07450981, 0.07843138, 0.09411765],\n",
              "           [0.01568628, 0.02352941, 0.01176471],\n",
              "           [0.01960784, 0.02745098, 0.01176471]],\n",
              "  \n",
              "          [[0.10980392, 0.16078432, 0.18431373],\n",
              "           [0.11764706, 0.16862746, 0.19607843],\n",
              "           [0.1254902 , 0.1764706 , 0.20392157],\n",
              "           ...,\n",
              "           [0.01960784, 0.02352941, 0.03137255],\n",
              "           [0.01568628, 0.01960784, 0.01176471],\n",
              "           [0.02745098, 0.03137255, 0.02745098]]],\n",
              "  \n",
              "  \n",
              "         ...,\n",
              "  \n",
              "  \n",
              "         [[[0.07843138, 0.05882353, 0.04705882],\n",
              "           [0.07450981, 0.05490196, 0.04313726],\n",
              "           [0.05882353, 0.05490196, 0.04313726],\n",
              "           ...,\n",
              "           [0.03921569, 0.03529412, 0.02745098],\n",
              "           [0.04705882, 0.04313726, 0.03529412],\n",
              "           [0.05098039, 0.04705882, 0.03921569]],\n",
              "  \n",
              "          [[0.08235294, 0.0627451 , 0.05098039],\n",
              "           [0.07843138, 0.0627451 , 0.05098039],\n",
              "           [0.07058824, 0.06666667, 0.04705882],\n",
              "           ...,\n",
              "           [0.03921569, 0.03529412, 0.02745098],\n",
              "           [0.03921569, 0.03529412, 0.02745098],\n",
              "           [0.04705882, 0.04313726, 0.03529412]],\n",
              "  \n",
              "          [[0.08235294, 0.0627451 , 0.05098039],\n",
              "           [0.08235294, 0.06666667, 0.04705882],\n",
              "           [0.07843138, 0.07058824, 0.04313726],\n",
              "           ...,\n",
              "           [0.04705882, 0.04313726, 0.03529412],\n",
              "           [0.04705882, 0.04313726, 0.03529412],\n",
              "           [0.05098039, 0.04705882, 0.03921569]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[0.12941177, 0.09803922, 0.05098039],\n",
              "           [0.13333334, 0.10196079, 0.05882353],\n",
              "           [0.13333334, 0.10196079, 0.05882353],\n",
              "           ...,\n",
              "           [0.10980392, 0.09803922, 0.20392157],\n",
              "           [0.11372549, 0.09803922, 0.22745098],\n",
              "           [0.09019608, 0.07843138, 0.16470589]],\n",
              "  \n",
              "          [[0.12941177, 0.09803922, 0.05490196],\n",
              "           [0.13333334, 0.10196079, 0.05882353],\n",
              "           [0.13333334, 0.10196079, 0.05882353],\n",
              "           ...,\n",
              "           [0.10588235, 0.09411765, 0.20392157],\n",
              "           [0.10588235, 0.09411765, 0.21960784],\n",
              "           [0.09803922, 0.08627451, 0.18431373]],\n",
              "  \n",
              "          [[0.12156863, 0.09019608, 0.04705882],\n",
              "           [0.1254902 , 0.09411765, 0.05098039],\n",
              "           [0.12941177, 0.09803922, 0.05490196],\n",
              "           ...,\n",
              "           [0.09411765, 0.09019608, 0.19607843],\n",
              "           [0.10196079, 0.09019608, 0.20784314],\n",
              "           [0.09803922, 0.07843138, 0.18431373]]],\n",
              "  \n",
              "  \n",
              "         [[[0.09803922, 0.15686275, 0.04705882],\n",
              "           [0.05882353, 0.14117648, 0.01176471],\n",
              "           [0.09019608, 0.16078432, 0.07058824],\n",
              "           ...,\n",
              "           [0.23921569, 0.32156864, 0.30588236],\n",
              "           [0.36078432, 0.44313726, 0.4392157 ],\n",
              "           [0.29411766, 0.34901962, 0.36078432]],\n",
              "  \n",
              "          [[0.04705882, 0.09803922, 0.02352941],\n",
              "           [0.07843138, 0.14509805, 0.02745098],\n",
              "           [0.09411765, 0.14117648, 0.05882353],\n",
              "           ...,\n",
              "           [0.4509804 , 0.5254902 , 0.5411765 ],\n",
              "           [0.58431375, 0.65882355, 0.69411767],\n",
              "           [0.40784314, 0.45882353, 0.5137255 ]],\n",
              "  \n",
              "          [[0.04705882, 0.09803922, 0.04313726],\n",
              "           [0.05882353, 0.11372549, 0.02352941],\n",
              "           [0.13333334, 0.15686275, 0.09411765],\n",
              "           ...,\n",
              "           [0.6039216 , 0.6745098 , 0.7137255 ],\n",
              "           [0.6156863 , 0.6862745 , 0.7529412 ],\n",
              "           [0.45490196, 0.5058824 , 0.5921569 ]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[0.39215687, 0.5058824 , 0.31764707],\n",
              "           [0.40392157, 0.5176471 , 0.32941177],\n",
              "           [0.40784314, 0.5254902 , 0.3372549 ],\n",
              "           ...,\n",
              "           [0.38039216, 0.5019608 , 0.32941177],\n",
              "           [0.38431373, 0.49411765, 0.32941177],\n",
              "           [0.35686275, 0.4745098 , 0.30980393]],\n",
              "  \n",
              "          [[0.40392157, 0.5176471 , 0.3254902 ],\n",
              "           [0.40784314, 0.5137255 , 0.3254902 ],\n",
              "           [0.41960785, 0.5294118 , 0.34117648],\n",
              "           ...,\n",
              "           [0.39607844, 0.5176471 , 0.34117648],\n",
              "           [0.3882353 , 0.49803922, 0.32941177],\n",
              "           [0.36078432, 0.4745098 , 0.30980393]],\n",
              "  \n",
              "          [[0.37254903, 0.49411765, 0.30588236],\n",
              "           [0.37254903, 0.48235294, 0.29803923],\n",
              "           [0.39607844, 0.5019608 , 0.31764707],\n",
              "           ...,\n",
              "           [0.3647059 , 0.4862745 , 0.3137255 ],\n",
              "           [0.37254903, 0.48235294, 0.31764707],\n",
              "           [0.36078432, 0.47058824, 0.3137255 ]]],\n",
              "  \n",
              "  \n",
              "         [[[0.28627452, 0.30588236, 0.29411766],\n",
              "           [0.38431373, 0.40392157, 0.44313726],\n",
              "           [0.3882353 , 0.41568628, 0.44705883],\n",
              "           ...,\n",
              "           [0.5294118 , 0.5882353 , 0.59607846],\n",
              "           [0.5294118 , 0.58431375, 0.6039216 ],\n",
              "           [0.79607844, 0.84313726, 0.8745098 ]],\n",
              "  \n",
              "          [[0.27058825, 0.28627452, 0.27450982],\n",
              "           [0.32941177, 0.34901962, 0.38039216],\n",
              "           [0.26666668, 0.29411766, 0.31764707],\n",
              "           ...,\n",
              "           [0.33333334, 0.37254903, 0.34901962],\n",
              "           [0.2784314 , 0.32156864, 0.3137255 ],\n",
              "           [0.47058824, 0.52156866, 0.5294118 ]],\n",
              "  \n",
              "          [[0.27058825, 0.28627452, 0.27450982],\n",
              "           [0.3529412 , 0.37254903, 0.39215687],\n",
              "           [0.24313726, 0.2784314 , 0.2901961 ],\n",
              "           ...,\n",
              "           [0.2901961 , 0.31764707, 0.27450982],\n",
              "           [0.20784314, 0.24313726, 0.21176471],\n",
              "           [0.24313726, 0.2901961 , 0.27058825]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[0.48235294, 0.5019608 , 0.3764706 ],\n",
              "           [0.5176471 , 0.5176471 , 0.4       ],\n",
              "           [0.5058824 , 0.5019608 , 0.39215687],\n",
              "           ...,\n",
              "           [0.42352942, 0.41960785, 0.34509805],\n",
              "           [0.24313726, 0.23529412, 0.21568628],\n",
              "           [0.10588235, 0.10588235, 0.10980392]],\n",
              "  \n",
              "          [[0.4509804 , 0.4745098 , 0.35686275],\n",
              "           [0.48235294, 0.4862745 , 0.37254903],\n",
              "           [0.5058824 , 0.49411765, 0.3882353 ],\n",
              "           ...,\n",
              "           [0.4509804 , 0.45490196, 0.36862746],\n",
              "           [0.25882354, 0.25490198, 0.23137255],\n",
              "           [0.10588235, 0.10588235, 0.10588235]],\n",
              "  \n",
              "          [[0.45490196, 0.47058824, 0.3529412 ],\n",
              "           [0.4745098 , 0.47843137, 0.36862746],\n",
              "           [0.5058824 , 0.5019608 , 0.39607844],\n",
              "           ...,\n",
              "           [0.45490196, 0.4509804 , 0.36862746],\n",
              "           [0.26666668, 0.25490198, 0.22745098],\n",
              "           [0.10588235, 0.10196079, 0.10196079]]]], dtype=float32),\n",
              "  array([[0., 1.],\n",
              "         [1., 0.],\n",
              "         [1., 0.],\n",
              "         ...,\n",
              "         [0., 1.],\n",
              "         [1., 0.],\n",
              "         [0., 1.]])),\n",
              " ['Veicolo', 'Animale'])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_generators(x_train, y_train):\n",
        "    \"\"\"\n",
        "    Crea i generatori di dati per data augmentation durante l'addestramento.\n",
        "    \"\"\"\n",
        "    print(\"Creazione dei generatori di dati con data augmentation...\")\n",
        "\n",
        "    # Generatore per data augmentation sul training set\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    train_generator = train_datagen.flow(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    return train_generator"
      ],
      "metadata": {
        "id": "bNKO2le4CG9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yYq_fcQLCG6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imposta la riproducibilità\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Avvio del sistema di riconoscimento automatico veicoli-animali\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Parte 1: Preparazione dei dati\n",
        "print(\"\\nPARTE 1: PREPARAZIONE DEI DATI\")\n",
        "print(\"-\" * 70)\n",
        "(x_train, y_train), (x_val, y_val), (x_test, y_test), class_names = load_and_prepare_cifar10()\n",
        "train_generator = create_data_generators(x_train, y_train)\n",
        "visualize_augmented_samples(x_train, y_train, class_names)\n",
        "\n",
        "# Parte 2: Addestramento del modello\n",
        "print(\"\\nPARTE 2: ADDESTRAMENTO DEL MODELLO\")\n",
        "print(\"-\" * 70)\n",
        "model = create_cnn_model()\n",
        "trained_model, history = train_model(model, train_generator, x_val, y_val)\n",
        "visualize_training_history(history)\n",
        "\n",
        "# Parte 3: Valutazione e predizione\n",
        "print(\"\\nPARTE 3: VALUTAZIONE E PREDIZIONE\")\n",
        "print(\"-\" * 70)\n",
        "y_pred, y_true_classes, y_pred_classes = evaluate_model(trained_model, x_test, y_test, class_names)\n",
        "visualize_incorrect_predictions(x_test, y_true_classes, y_pred_classes, class_names)\n",
        "analyze_class_activation_maps(trained_model, x_test, y_true_classes, class_names)\n",
        "\n",
        "# Salva il modello finale\n",
        "trained_model.save('vehicle_animal_classifier_final.h5')\n",
        "print(\"\\nModello finale salvato come 'vehicle_animal_classifier_final.h5'\")\n",
        "\n",
        "print(\"\\nSistema di riconoscimento automatico completato con successo!\")\n",
        "print(\"=\" * 70)"
      ],
      "metadata": {
        "id": "z5TQ3EXECG3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tI9eSNJ4CG1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7mbAKvQ0C0gw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c94d83a-ab67-4ea1-ea67-67f081ec3af7"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avvio del sistema di riconoscimento automatico veicoli-animali\n",
            "======================================================================\n",
            "\n",
            "PARTE 1: PREPARAZIONE DEI DATI\n",
            "----------------------------------------------------------------------\n",
            "Caricamento del dataset CIFAR-10...\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
            "Dati preparati. Forma dei dati:\n",
            "  Train: (40000, 32, 32, 3) con 40000 etichette\n",
            "  Validation: (10000, 32, 32, 3) con 10000 etichette\n",
            "  Test: (10000, 32, 32, 3) con 10000 etichette\n",
            "Creazione dei generatori di dati con data augmentation...\n",
            "Esempi di data augmentation salvati in 'data_augmentation_examples.png'\n",
            "\n",
            "PARTE 2: ADDESTRAMENTO DEL MODELLO\n",
            "----------------------------------------------------------------------\n",
            "Creazione del modello CNN...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m524,544\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m514\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">814,882</span> (3.11 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m814,882\u001b[0m (3.11 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">813,474</span> (3.10 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m813,474\u001b[0m (3.10 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> (5.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,408\u001b[0m (5.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inizio addestramento del modello...\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.8301 - loss: 0.4386"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 345ms/step - accuracy: 0.8302 - loss: 0.4385 - val_accuracy: 0.8973 - val_loss: 0.2491 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.8975 - loss: 0.2523"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 335ms/step - accuracy: 0.8975 - loss: 0.2523 - val_accuracy: 0.9111 - val_loss: 0.2367 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 322ms/step - accuracy: 0.9046 - loss: 0.2388 - val_accuracy: 0.9025 - val_loss: 0.2417 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.9158 - loss: 0.2098"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 335ms/step - accuracy: 0.9158 - loss: 0.2098 - val_accuracy: 0.9180 - val_loss: 0.2113 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.9210 - loss: 0.2050"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m398s\u001b[0m 318ms/step - accuracy: 0.9210 - loss: 0.2050 - val_accuracy: 0.9444 - val_loss: 0.1446 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 335ms/step - accuracy: 0.9247 - loss: 0.1932 - val_accuracy: 0.8748 - val_loss: 0.3197 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 338ms/step - accuracy: 0.9293 - loss: 0.1833 - val_accuracy: 0.9405 - val_loss: 0.1607 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 340ms/step - accuracy: 0.9314 - loss: 0.1714 - val_accuracy: 0.9194 - val_loss: 0.2329 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.9415 - loss: 0.1521"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 322ms/step - accuracy: 0.9415 - loss: 0.1521 - val_accuracy: 0.9503 - val_loss: 0.1272 - learning_rate: 5.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.9456 - loss: 0.1437"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 318ms/step - accuracy: 0.9456 - loss: 0.1437 - val_accuracy: 0.9541 - val_loss: 0.1176 - learning_rate: 5.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 318ms/step - accuracy: 0.9457 - loss: 0.1446 - val_accuracy: 0.9530 - val_loss: 0.1254 - learning_rate: 5.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.9500 - loss: 0.1294"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 317ms/step - accuracy: 0.9500 - loss: 0.1294 - val_accuracy: 0.9571 - val_loss: 0.1110 - learning_rate: 5.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 337ms/step - accuracy: 0.9495 - loss: 0.1291 - val_accuracy: 0.9361 - val_loss: 0.1594 - learning_rate: 5.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 333ms/step - accuracy: 0.9493 - loss: 0.1295 - val_accuracy: 0.9518 - val_loss: 0.1256 - learning_rate: 5.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.9509 - loss: 0.1295"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 335ms/step - accuracy: 0.9509 - loss: 0.1295 - val_accuracy: 0.9590 - val_loss: 0.1105 - learning_rate: 5.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.9569 - loss: 0.1155"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 321ms/step - accuracy: 0.9568 - loss: 0.1155 - val_accuracy: 0.9607 - val_loss: 0.1098 - learning_rate: 5.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.9522 - loss: 0.1267"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 322ms/step - accuracy: 0.9522 - loss: 0.1267 - val_accuracy: 0.9654 - val_loss: 0.1012 - learning_rate: 5.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 321ms/step - accuracy: 0.9539 - loss: 0.1191 - val_accuracy: 0.9619 - val_loss: 0.1038 - learning_rate: 5.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 318ms/step - accuracy: 0.9568 - loss: 0.1156 - val_accuracy: 0.9544 - val_loss: 0.1169 - learning_rate: 5.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 335ms/step - accuracy: 0.9555 - loss: 0.1177 - val_accuracy: 0.9515 - val_loss: 0.1277 - learning_rate: 5.0000e-04\n",
            "Addestramento completato in 8476.70 secondi\n",
            "Caricamento del miglior modello da: best_model_vehicle_animal.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grafici di addestramento salvati in 'training_history.png'\n",
            "\n",
            "PARTE 3: VALUTAZIONE E PREDIZIONE\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Valutazione del modello sul set di test...\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - accuracy: 0.9627 - loss: 0.1015\n",
            "Test accuracy: 0.9630\n",
            "Test loss: 0.0976\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 68ms/step\n",
            "Matrice di confusione salvata in 'confusion_matrix.png'\n",
            "\n",
            "Report di classificazione:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Veicolo       0.95      0.96      0.95      4000\n",
            "     Animale       0.97      0.96      0.97      6000\n",
            "\n",
            "    accuracy                           0.96     10000\n",
            "   macro avg       0.96      0.96      0.96     10000\n",
            "weighted avg       0.96      0.96      0.96     10000\n",
            "\n",
            "Report di classificazione salvato in 'classification_report.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Esempi di 20 predizioni errate salvate in 'incorrect_predictions.png'\n",
            "Errore durante la generazione delle mappe di attivazione: The layer sequential has never been called and thus has no defined output.\n",
            "\n",
            "Modello finale salvato come 'vehicle_animal_classifier_final.h5'\n",
            "\n",
            "Sistema di riconoscimento automatico completato con successo!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Sistema di Riconoscimento Automatico Veicoli-Animali\n",
        "# VisionTech Solutions\n",
        "# Classificatore basato su CNN con Keras\n",
        "\n",
        "\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# PARTE 1: PREPARAZIONE DEI DATI\n",
        "# ------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "def create_data_generators(x_train, y_train):\n",
        "    \"\"\"\n",
        "    Crea i generatori di dati per data augmentation durante l'addestramento.\n",
        "    \"\"\"\n",
        "    print(\"Creazione dei generatori di dati con data augmentation...\")\n",
        "\n",
        "    # Generatore per data augmentation sul training set\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    train_generator = train_datagen.flow(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    return train_generator\n",
        "\n",
        "def visualize_augmented_samples(x_train, y_train, class_names):\n",
        "    \"\"\"\n",
        "    Visualizza esempi di data augmentation per verificare la trasformazione.\n",
        "    \"\"\"\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    # Prendi solo alcune immagini di esempio\n",
        "    sample_images = x_train[:5]\n",
        "    sample_labels = y_train[:5]\n",
        "\n",
        "    # Genera alcune immagini aumentate\n",
        "    aug_iter = train_datagen.flow(sample_images, sample_labels, batch_size=1)\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i in range(5):\n",
        "        # Immagine originale\n",
        "        plt.subplot(2, 5, i+1)\n",
        "        plt.imshow(sample_images[i])\n",
        "        plt.title(f\"Orig: {class_names[np.argmax(sample_labels[i])]}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Immagine aumentata\n",
        "        aug_img = next(aug_iter)[0][0]\n",
        "        plt.subplot(2, 5, i+6)\n",
        "        plt.imshow(aug_img)\n",
        "        plt.title(\"Aumentata\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('data_augmentation_examples.png')\n",
        "    plt.close()\n",
        "    print(\"Esempi di data augmentation salvati in 'data_augmentation_examples.png'\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# PARTE 2: ADDESTRAMENTO DEL MODELLO\n",
        "# ------------------------------------------------------\n",
        "\n",
        "def create_cnn_model(input_shape=(32, 32, 3)):\n",
        "    \"\"\"\n",
        "    Crea un modello CNN per la classificazione binaria veicoli/animali\n",
        "    \"\"\"\n",
        "    print(\"Creazione del modello CNN...\")\n",
        "\n",
        "    # Definiamo l'input layer esplicitamente\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # Primo blocco convoluzionale\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # Secondo blocco convoluzionale\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Terzo blocco convoluzionale\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "\n",
        "    # Livelli completamente connessi\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(2, activation='softmax')(x)  # Output binario: veicolo o animale\n",
        "\n",
        "    # Creazione del modello utilizzando il modello funzionale API\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"vehicle_animal_classifier\")\n",
        "\n",
        "    # Compilazione del modello\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_model(model, train_generator, x_val, y_val, epochs=20):\n",
        "    \"\"\"\n",
        "    Addestra il modello CNN con i dati preparati\n",
        "    \"\"\"\n",
        "    print(\"Inizio addestramento del modello...\")\n",
        "\n",
        "    # Callback per salvare il miglior modello durante l'addestramento\n",
        "    checkpoint_filepath = 'best_model_vehicle_animal.h5'\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        save_weights_only=False,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        save_best_only=True\n",
        "    )\n",
        "\n",
        "    # Callback per early stopping se non ci sono miglioramenti\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=5,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    # Callback per ridurre il learning rate se non ci sono miglioramenti\n",
        "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=0.00001\n",
        "    )\n",
        "\n",
        "    # Addestramento del modello\n",
        "    start_time = time.time()\n",
        "\n",
        "    steps_per_epoch = len(train_generator)\n",
        "\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=epochs,\n",
        "        validation_data=(x_val, y_val),\n",
        "        callbacks=[model_checkpoint_callback, early_stopping, reduce_lr]\n",
        "    )\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"Addestramento completato in {training_time:.2f} secondi\")\n",
        "\n",
        "    # Carica il miglior modello (se è stato salvato)\n",
        "    if os.path.exists(checkpoint_filepath):\n",
        "        print(f\"Caricamento del miglior modello da: {checkpoint_filepath}\")\n",
        "        model = keras.models.load_model(checkpoint_filepath)\n",
        "\n",
        "    return model, history\n",
        "\n",
        "def visualize_training_history(history):\n",
        "    \"\"\"\n",
        "    Visualizza i grafici dell'andamento dell'addestramento del modello\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot accuratezza\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Accuratezza del Modello')\n",
        "    plt.ylabel('Accuratezza')\n",
        "    plt.xlabel('Epoca')\n",
        "    plt.legend(loc='lower right')\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss del Modello')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoca')\n",
        "    plt.legend(loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png')\n",
        "    plt.close()\n",
        "    print(\"Grafici di addestramento salvati in 'training_history.png'\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# PARTE 3: VALUTAZIONE E PREDIZIONE\n",
        "# ------------------------------------------------------\n",
        "\n",
        "def evaluate_model(model, x_test, y_test, class_names):\n",
        "    \"\"\"\n",
        "    Valuta il modello addestrato sul set di test\n",
        "    \"\"\"\n",
        "    print(\"\\nValutazione del modello sul set di test...\")\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "    print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "    print(f\"Test loss: {test_loss:.4f}\")\n",
        "\n",
        "    # Predizioni sul set di test\n",
        "    y_pred = model.predict(x_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "    # Calcola e visualizza la matrice di confusione\n",
        "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predizione')\n",
        "    plt.ylabel('Valore Reale')\n",
        "    plt.title('Matrice di Confusione')\n",
        "    plt.savefig('confusion_matrix.png')\n",
        "    plt.close()\n",
        "    print(\"Matrice di confusione salvata in 'confusion_matrix.png'\")\n",
        "\n",
        "    # Report di classificazione\n",
        "    print(\"\\nReport di classificazione:\")\n",
        "    print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))\n",
        "\n",
        "    # Salvare il report di classificazione come CSV\n",
        "    report = classification_report(y_true_classes, y_pred_classes, target_names=class_names, output_dict=True)\n",
        "    df_report = pd.DataFrame(report).transpose()\n",
        "    df_report.to_csv('classification_report.csv')\n",
        "    print(\"Report di classificazione salvato in 'classification_report.csv'\")\n",
        "\n",
        "    return y_pred, y_true_classes, y_pred_classes\n",
        "\n",
        "def visualize_incorrect_predictions(x_test, y_true_classes, y_pred_classes, class_names, n=20):\n",
        "    \"\"\"\n",
        "    Visualizza esempi di predizioni errate per l'analisi dell'errore\n",
        "    \"\"\"\n",
        "    incorrect_indices = np.where(y_true_classes != y_pred_classes)[0]\n",
        "\n",
        "    if len(incorrect_indices) == 0:\n",
        "        print(\"Nessuna predizione errata trovata!\")\n",
        "        return\n",
        "\n",
        "    # Limita il numero di immagini da visualizzare\n",
        "    n = min(n, len(incorrect_indices))\n",
        "\n",
        "    plt.figure(figsize=(20, n))\n",
        "    for i, idx in enumerate(incorrect_indices[:n]):\n",
        "        plt.subplot(n // 4 + 1, 4, i + 1)\n",
        "        plt.imshow(x_test[idx])\n",
        "        plt.title(f\"Vero: {class_names[y_true_classes[idx]]}\\nPred: {class_names[y_pred_classes[idx]]}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('incorrect_predictions.png')\n",
        "    plt.close()\n",
        "    print(f\"Esempi di {n} predizioni errate salvate in 'incorrect_predictions.png'\")\n",
        "\n",
        "def analyze_class_activation_maps(model, x_test, y_true_classes, class_names, n=5):\n",
        "    \"\"\"\n",
        "    Analizza le mappe di attivazione della classe per capire su quali parti\n",
        "    dell'immagine il modello si sta concentrando per fare la predizione.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Crea un modello che restituisce sia la predizione che l'ultima mappa di attivazione convoluzionale\n",
        "        last_conv_layer_name = None\n",
        "        for layer in reversed(model.layers):\n",
        "            if isinstance(layer, layers.Conv2D):\n",
        "                last_conv_layer_name = layer.name\n",
        "                break\n",
        "\n",
        "        if last_conv_layer_name is None:\n",
        "            print(\"Nessun layer convoluzionale trovato nel modello.\")\n",
        "            return\n",
        "\n",
        "        # Modello per estrarre le mappe di attivazione\n",
        "        grad_model = tf.keras.models.Model(\n",
        "            inputs=[model.inputs],\n",
        "            outputs=[\n",
        "                model.get_layer(last_conv_layer_name).output,\n",
        "                model.output\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Seleziona alcune immagini\n",
        "        selected_indices = np.random.choice(len(x_test), n, replace=False)\n",
        "\n",
        "        plt.figure(figsize=(15, n * 3))\n",
        "        for i, idx in enumerate(selected_indices):\n",
        "            img = x_test[idx]\n",
        "            img_array = np.expand_dims(img, axis=0)\n",
        "\n",
        "            # Calcola le mappe di attivazione\n",
        "            with tf.GradientTape() as tape:\n",
        "                conv_outputs, predictions = grad_model(img_array)\n",
        "                class_idx = y_true_classes[idx]\n",
        "                loss = predictions[:, class_idx]\n",
        "\n",
        "            # Estrai gli output dell'ultimo layer convoluzionale\n",
        "            output = conv_outputs[0]\n",
        "\n",
        "            # Crea una mappa di calore ponderata\n",
        "            weights = tape.gradient(loss, conv_outputs)[0]\n",
        "            cam = np.mean(output * weights[..., np.newaxis], axis=(0, 1))\n",
        "\n",
        "            cam = np.maximum(cam, 0)  # ReLU\n",
        "            heatmap = cam / np.max(cam)\n",
        "\n",
        "            # Ridimensiona la mappa di calore alle dimensioni dell'immagine originale\n",
        "            import cv2\n",
        "            heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "\n",
        "            # Converti la mappa di calore in RGB\n",
        "            heatmap = np.uint8(255 * heatmap)\n",
        "            heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "            # Sovrapponi la mappa di calore all'immagine originale\n",
        "            superimposed_img = heatmap * 0.4 + img * 255\n",
        "            superimposed_img = np.clip(superimposed_img, 0, 255).astype('uint8')\n",
        "\n",
        "            # Visualizza l'immagine originale e la mappa di calore\n",
        "            plt.subplot(n, 2, i * 2 + 1)\n",
        "            plt.imshow(img)\n",
        "            plt.title(f\"Originale: {class_names[class_idx]}\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(n, 2, i * 2 + 2)\n",
        "            plt.imshow(superimposed_img)\n",
        "            plt.title(\"Mappa di Attivazione\")\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('class_activation_maps.png')\n",
        "        plt.close()\n",
        "        print(\"Mappe di attivazione delle classi salvate in 'class_activation_maps.png'\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Errore durante la generazione delle mappe di attivazione: {e}\")\n",
        "\n",
        "def main():\n",
        "    # Imposta la riproducibilità\n",
        "    tf.random.set_seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    print(\"Avvio del sistema di riconoscimento automatico veicoli-animali\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Parte 1: Preparazione dei dati\n",
        "    print(\"\\nPARTE 1: PREPARAZIONE DEI DATI\")\n",
        "    print(\"-\" * 70)\n",
        "    (x_train, y_train), (x_val, y_val), (x_test, y_test), class_names = load_and_prepare_cifar10()\n",
        "    train_generator = create_data_generators(x_train, y_train)\n",
        "    visualize_augmented_samples(x_train, y_train, class_names)\n",
        "\n",
        "    # Parte 2: Addestramento del modello\n",
        "    print(\"\\nPARTE 2: ADDESTRAMENTO DEL MODELLO\")\n",
        "    print(\"-\" * 70)\n",
        "    model = create_cnn_model()\n",
        "    trained_model, history = train_model(model, train_generator, x_val, y_val)\n",
        "    visualize_training_history(history)\n",
        "\n",
        "    # Parte 3: Valutazione e predizione\n",
        "    print(\"\\nPARTE 3: VALUTAZIONE E PREDIZIONE\")\n",
        "    print(\"-\" * 70)\n",
        "    y_pred, y_true_classes, y_pred_classes = evaluate_model(trained_model, x_test, y_test, class_names)\n",
        "    visualize_incorrect_predictions(x_test, y_true_classes, y_pred_classes, class_names)\n",
        "    analyze_class_activation_maps(trained_model, x_test, y_true_classes, class_names)\n",
        "\n",
        "    # Salva il modello finale\n",
        "    trained_model.save('vehicle_animal_classifier_final.h5')\n",
        "    print(\"\\nModello finale salvato come 'vehicle_animal_classifier_final.h5'\")\n",
        "\n",
        "    print(\"\\nSistema di riconoscimento automatico completato con successo!\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}