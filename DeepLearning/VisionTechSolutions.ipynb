{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZDi6DTjcRIOdFfsoQoNIG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mighty-mass/ai-engineer-course/blob/main/DeepLearning/VisionTechSolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Riconoscimento di animali per auto a guida autonoma\n",
        "VisionTech Solutions vuole sviluppare un sistema di riconoscimento automatico delle immagini per distinguere tra veicoli e animali, con l'obiettivo di ottimizzare le operazioni di monitoraggio della fauna nelle aree urbane, evitando incidenti stradali e proteggendo sia gli animali che i veicoli.\n",
        "\n",
        "VisionTech Solutions collabora con le amministrazioni comunali per implementare un sistema di monitoraggio in tempo reale nelle città, utilizzando telecamere installate lungo le strade per identificare e classificare veicoli e animali. Questo sistema aiuterà a prevenire incidenti stradali causati dall'attraversamento improvviso di animali, avvisando i guidatori tramite segnali stradali elettronici.\n",
        "\n",
        "Benefici:\n",
        "\n",
        "1. Automazione dei Processi:\n",
        "- Riduzione del tempo e delle risorse per monitorare manualmente le aree urbane.\n",
        "- Rilevamento automatico e in tempo reale di animali e veicoli.\n",
        "2. Aumento della Precisione:\n",
        "- Utilizzo di una rete neurale convoluzionale (CNN) per garantire alta precisione nella classificazione delle immagini.\n",
        "- Minimizzazione degli errori umani.\n",
        "3. Efficienza Operativa:\n",
        "- Processamento rapido e accurato di grandi volumi di dati, migliorando la risposta agli eventi.\n",
        "- Maggiore sicurezza per i cittadini e riduzione dei danni ai veicoli.\n",
        "4. Applicazioni Multiple:\n",
        "- Sorveglianza e monitoraggio del traffico.\n",
        "- Analisi del comportamento animale nelle aree urbane.\n",
        "- Utilizzo dei dati per migliorare le politiche di sicurezza stradale.\n",
        "\n",
        "## Dettagli del Progetto:\n",
        "\n",
        "1. Dataset:\n",
        "- Utilizzo del dataset CIFAR, contenente migliaia di immagini etichettate in varie categorie, inclusi veicoli e animali.\n",
        "2. Algoritmo:\n",
        "- Implementazione di una rete neurale convoluzionale (CNN) per l'analisi e la classificazione delle immagini.\n",
        "3. Output:\n",
        "- Il sistema classificherà correttamente ogni immagine come veicolo o animale.\n",
        "\n",
        "## Valutazione del Modello:\n",
        "\n",
        "- **Accuratezza**: Proporzione di immagini classificate correttamente rispetto al totale.\n",
        "- **Precisione**: Qualità delle predizioni positive, indicando la proporzione di immagini correttamente identificate.\n",
        "\n",
        "## Analisi dei Risultati:\n",
        "\n",
        "- Identificazione di eventuali pattern di errore.\n",
        "- Valutazione delle categorie di immagini confuse sistematicamente.\n",
        "- Esame delle immagini errate e riflessione su possibili migliorie al modello.\n",
        "\n",
        "## Risultato Finale:\n",
        "\n",
        "- Presentazione completa della rete neurale convoluzionale e delle sue capacità di discriminazione tra veicoli e animali.\n",
        "- Discussione dettagliata delle metriche utilizzate e un'analisi critica delle prestazioni e limitazioni del modello.\n",
        "\n",
        "Questo progetto fornirà a VisionTech Solutions un sistema efficace per migliorare la sicurezza stradale e la gestione della fauna nelle aree urbane, dimostrando le competenze pratiche nell'applicazione del machine learning al riconoscimento delle immagini."
      ],
      "metadata": {
        "id": "Gb3Cd6ZyC09i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mbAKvQ0C0gw"
      },
      "outputs": [],
      "source": [
        "# Sistema di Riconoscimento Automatico Veicoli-Animali\n",
        "# VisionTech Solutions\n",
        "# Classificatore basato su CNN con Keras\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# PARTE 1: PREPARAZIONE DEI DATI\n",
        "# ------------------------------------------------------\n",
        "\n",
        "def load_and_prepare_cifar10():\n",
        "    \"\"\"\n",
        "    Carica e prepara il dataset CIFAR-10, selezionando solo le classi di interesse:\n",
        "    - Veicoli: automobile, camion, nave, aereo\n",
        "    - Animali: uccello, gatto, cervo, cane, rana, cavallo\n",
        "    \"\"\"\n",
        "    print(\"Caricamento del dataset CIFAR-10...\")\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "    # Le classi di CIFAR-10 sono:\n",
        "    # 0: aereo, 1: automobile, 2: uccello, 3: gatto, 4: cervo,\n",
        "    # 5: cane, 6: rana, 7: cavallo, 8: nave, 9: camion\n",
        "\n",
        "    # Mappiamo le classi originali a classi binarie:\n",
        "    # - Veicoli (0): aereo (0), automobile (1), nave (8), camion (9)\n",
        "    # - Animali (1): uccello (2), gatto (3), cervo (4), cane (5), rana (6), cavallo (7)\n",
        "\n",
        "    # Creazione della mappa delle classi\n",
        "    class_mapping = {\n",
        "        0: 0,  # aereo -> veicolo\n",
        "        1: 0,  # automobile -> veicolo\n",
        "        2: 1,  # uccello -> animale\n",
        "        3: 1,  # gatto -> animale\n",
        "        4: 1,  # cervo -> animale\n",
        "        5: 1,  # cane -> animale\n",
        "        6: 1,  # rana -> animale\n",
        "        7: 1,  # cavallo -> animale\n",
        "        8: 0,  # nave -> veicolo\n",
        "        9: 0   # camion -> veicolo\n",
        "    }\n",
        "\n",
        "    # Applicazione della mappatura\n",
        "    y_train_binary = np.array([class_mapping[y[0]] for y in y_train])\n",
        "    y_test_binary = np.array([class_mapping[y[0]] for y in y_test])\n",
        "\n",
        "    # Separazione degli indici di validazione dal set di addestramento\n",
        "    x_train, x_val, y_train_binary, y_val_binary = train_test_split(\n",
        "        x_train, y_train_binary, test_size=0.2, random_state=42, stratify=y_train_binary\n",
        "    )\n",
        "\n",
        "    # Normalizzazione dei dati (0-255 -> 0-1)\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_val = x_val.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "    # One-hot encoding per le etichette (anche se sono binarie)\n",
        "    y_train_binary = to_categorical(y_train_binary, 2)\n",
        "    y_val_binary = to_categorical(y_val_binary, 2)\n",
        "    y_test_binary = to_categorical(y_test_binary, 2)\n",
        "\n",
        "    class_names = ['Veicolo', 'Animale']\n",
        "\n",
        "    print(f\"Dati preparati. Forma dei dati:\")\n",
        "    print(f\"  Train: {x_train.shape} con {len(y_train_binary)} etichette\")\n",
        "    print(f\"  Validation: {x_val.shape} con {len(y_val_binary)} etichette\")\n",
        "    print(f\"  Test: {x_test.shape} con {len(y_test_binary)} etichette\")\n",
        "\n",
        "    return (x_train, y_train_binary), (x_val, y_val_binary), (x_test, y_test_binary), class_names\n",
        "\n",
        "def create_data_generators(x_train, y_train):\n",
        "    \"\"\"\n",
        "    Crea i generatori di dati per data augmentation durante l'addestramento.\n",
        "    \"\"\"\n",
        "    print(\"Creazione dei generatori di dati con data augmentation...\")\n",
        "\n",
        "    # Generatore per data augmentation sul training set\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    train_generator = train_datagen.flow(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    return train_generator\n",
        "\n",
        "def visualize_augmented_samples(x_train, y_train, class_names):\n",
        "    \"\"\"\n",
        "    Visualizza esempi di data augmentation per verificare la trasformazione.\n",
        "    \"\"\"\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    # Prendi solo alcune immagini di esempio\n",
        "    sample_images = x_train[:5]\n",
        "    sample_labels = y_train[:5]\n",
        "\n",
        "    # Genera alcune immagini aumentate\n",
        "    aug_iter = train_datagen.flow(sample_images, sample_labels, batch_size=1)\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i in range(5):\n",
        "        # Immagine originale\n",
        "        plt.subplot(2, 5, i+1)\n",
        "        plt.imshow(sample_images[i])\n",
        "        plt.title(f\"Orig: {class_names[np.argmax(sample_labels[i])]}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Immagine aumentata\n",
        "        aug_img = next(aug_iter)[0][0]\n",
        "        plt.subplot(2, 5, i+6)\n",
        "        plt.imshow(aug_img)\n",
        "        plt.title(\"Aumentata\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('data_augmentation_examples.png')\n",
        "    plt.close()\n",
        "    print(\"Esempi di data augmentation salvati in 'data_augmentation_examples.png'\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# PARTE 2: ADDESTRAMENTO DEL MODELLO\n",
        "# ------------------------------------------------------\n",
        "\n",
        "def create_cnn_model(input_shape=(32, 32, 3)):\n",
        "    \"\"\"\n",
        "    Crea un modello CNN per la classificazione binaria veicoli/animali\n",
        "    \"\"\"\n",
        "    print(\"Creazione del modello CNN...\")\n",
        "\n",
        "    # Definiamo l'input layer esplicitamente\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # Primo blocco convoluzionale\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # Secondo blocco convoluzionale\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Terzo blocco convoluzionale\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "\n",
        "    # Livelli completamente connessi\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(2, activation='softmax')(x)  # Output binario: veicolo o animale\n",
        "\n",
        "    # Creazione del modello utilizzando il modello funzionale API\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"vehicle_animal_classifier\")\n",
        "\n",
        "    # Compilazione del modello\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_model(model, train_generator, x_val, y_val, epochs=20):\n",
        "    \"\"\"\n",
        "    Addestra il modello CNN con i dati preparati\n",
        "    \"\"\"\n",
        "    print(\"Inizio addestramento del modello...\")\n",
        "\n",
        "    # Callback per salvare il miglior modello durante l'addestramento\n",
        "    checkpoint_filepath = 'best_model_vehicle_animal.h5'\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        save_weights_only=False,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        save_best_only=True\n",
        "    )\n",
        "\n",
        "    # Callback per early stopping se non ci sono miglioramenti\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=5,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    # Callback per ridurre il learning rate se non ci sono miglioramenti\n",
        "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=0.00001\n",
        "    )\n",
        "\n",
        "    # Addestramento del modello\n",
        "    start_time = time.time()\n",
        "\n",
        "    steps_per_epoch = len(train_generator)\n",
        "\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=epochs,\n",
        "        validation_data=(x_val, y_val),\n",
        "        callbacks=[model_checkpoint_callback, early_stopping, reduce_lr]\n",
        "    )\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"Addestramento completato in {training_time:.2f} secondi\")\n",
        "\n",
        "    # Carica il miglior modello (se è stato salvato)\n",
        "    if os.path.exists(checkpoint_filepath):\n",
        "        print(f\"Caricamento del miglior modello da: {checkpoint_filepath}\")\n",
        "        model = keras.models.load_model(checkpoint_filepath)\n",
        "\n",
        "    return model, history\n",
        "\n",
        "def visualize_training_history(history):\n",
        "    \"\"\"\n",
        "    Visualizza i grafici dell'andamento dell'addestramento del modello\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot accuratezza\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Accuratezza del Modello')\n",
        "    plt.ylabel('Accuratezza')\n",
        "    plt.xlabel('Epoca')\n",
        "    plt.legend(loc='lower right')\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss del Modello')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoca')\n",
        "    plt.legend(loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png')\n",
        "    plt.close()\n",
        "    print(\"Grafici di addestramento salvati in 'training_history.png'\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# PARTE 3: VALUTAZIONE E PREDIZIONE\n",
        "# ------------------------------------------------------\n",
        "\n",
        "def evaluate_model(model, x_test, y_test, class_names):\n",
        "    \"\"\"\n",
        "    Valuta il modello addestrato sul set di test\n",
        "    \"\"\"\n",
        "    print(\"\\nValutazione del modello sul set di test...\")\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "    print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "    print(f\"Test loss: {test_loss:.4f}\")\n",
        "\n",
        "    # Predizioni sul set di test\n",
        "    y_pred = model.predict(x_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "    # Calcola e visualizza la matrice di confusione\n",
        "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predizione')\n",
        "    plt.ylabel('Valore Reale')\n",
        "    plt.title('Matrice di Confusione')\n",
        "    plt.savefig('confusion_matrix.png')\n",
        "    plt.close()\n",
        "    print(\"Matrice di confusione salvata in 'confusion_matrix.png'\")\n",
        "\n",
        "    # Report di classificazione\n",
        "    print(\"\\nReport di classificazione:\")\n",
        "    print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))\n",
        "\n",
        "    # Salvare il report di classificazione come CSV\n",
        "    report = classification_report(y_true_classes, y_pred_classes, target_names=class_names, output_dict=True)\n",
        "    df_report = pd.DataFrame(report).transpose()\n",
        "    df_report.to_csv('classification_report.csv')\n",
        "    print(\"Report di classificazione salvato in 'classification_report.csv'\")\n",
        "\n",
        "    return y_pred, y_true_classes, y_pred_classes\n",
        "\n",
        "def visualize_incorrect_predictions(x_test, y_true_classes, y_pred_classes, class_names, n=20):\n",
        "    \"\"\"\n",
        "    Visualizza esempi di predizioni errate per l'analisi dell'errore\n",
        "    \"\"\"\n",
        "    incorrect_indices = np.where(y_true_classes != y_pred_classes)[0]\n",
        "\n",
        "    if len(incorrect_indices) == 0:\n",
        "        print(\"Nessuna predizione errata trovata!\")\n",
        "        return\n",
        "\n",
        "    # Limita il numero di immagini da visualizzare\n",
        "    n = min(n, len(incorrect_indices))\n",
        "\n",
        "    plt.figure(figsize=(20, n))\n",
        "    for i, idx in enumerate(incorrect_indices[:n]):\n",
        "        plt.subplot(n // 4 + 1, 4, i + 1)\n",
        "        plt.imshow(x_test[idx])\n",
        "        plt.title(f\"Vero: {class_names[y_true_classes[idx]]}\\nPred: {class_names[y_pred_classes[idx]]}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('incorrect_predictions.png')\n",
        "    plt.close()\n",
        "    print(f\"Esempi di {n} predizioni errate salvate in 'incorrect_predictions.png'\")\n",
        "\n",
        "def analyze_class_activation_maps(model, x_test, y_true_classes, class_names, n=5):\n",
        "    \"\"\"\n",
        "    Analizza le mappe di attivazione della classe per capire su quali parti\n",
        "    dell'immagine il modello si sta concentrando per fare la predizione.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Crea un modello che restituisce sia la predizione che l'ultima mappa di attivazione convoluzionale\n",
        "        last_conv_layer_name = None\n",
        "        for layer in reversed(model.layers):\n",
        "            if isinstance(layer, layers.Conv2D):\n",
        "                last_conv_layer_name = layer.name\n",
        "                break\n",
        "\n",
        "        if last_conv_layer_name is None:\n",
        "            print(\"Nessun layer convoluzionale trovato nel modello.\")\n",
        "            return\n",
        "\n",
        "        # Modello per estrarre le mappe di attivazione\n",
        "        grad_model = tf.keras.models.Model(\n",
        "            inputs=[model.inputs],\n",
        "            outputs=[\n",
        "                model.get_layer(last_conv_layer_name).output,\n",
        "                model.output\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Seleziona alcune immagini\n",
        "        selected_indices = np.random.choice(len(x_test), n, replace=False)\n",
        "\n",
        "        plt.figure(figsize=(15, n * 3))\n",
        "        for i, idx in enumerate(selected_indices):\n",
        "            img = x_test[idx]\n",
        "            img_array = np.expand_dims(img, axis=0)\n",
        "\n",
        "            # Calcola le mappe di attivazione\n",
        "            with tf.GradientTape() as tape:\n",
        "                conv_outputs, predictions = grad_model(img_array)\n",
        "                class_idx = y_true_classes[idx]\n",
        "                loss = predictions[:, class_idx]\n",
        "\n",
        "            # Estrai gli output dell'ultimo layer convoluzionale\n",
        "            output = conv_outputs[0]\n",
        "\n",
        "            # Crea una mappa di calore ponderata\n",
        "            weights = tape.gradient(loss, conv_outputs)[0]\n",
        "            cam = np.mean(output * weights[..., np.newaxis], axis=(0, 1))\n",
        "\n",
        "            cam = np.maximum(cam, 0)  # ReLU\n",
        "            heatmap = cam / np.max(cam)\n",
        "\n",
        "            # Ridimensiona la mappa di calore alle dimensioni dell'immagine originale\n",
        "            import cv2\n",
        "            heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "\n",
        "            # Converti la mappa di calore in RGB\n",
        "            heatmap = np.uint8(255 * heatmap)\n",
        "            heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "            # Sovrapponi la mappa di calore all'immagine originale\n",
        "            superimposed_img = heatmap * 0.4 + img * 255\n",
        "            superimposed_img = np.clip(superimposed_img, 0, 255).astype('uint8')\n",
        "\n",
        "            # Visualizza l'immagine originale e la mappa di calore\n",
        "            plt.subplot(n, 2, i * 2 + 1)\n",
        "            plt.imshow(img)\n",
        "            plt.title(f\"Originale: {class_names[class_idx]}\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(n, 2, i * 2 + 2)\n",
        "            plt.imshow(superimposed_img)\n",
        "            plt.title(\"Mappa di Attivazione\")\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('class_activation_maps.png')\n",
        "        plt.close()\n",
        "        print(\"Mappe di attivazione delle classi salvate in 'class_activation_maps.png'\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Errore durante la generazione delle mappe di attivazione: {e}\")\n",
        "\n",
        "def main():\n",
        "    # Imposta la riproducibilità\n",
        "    tf.random.set_seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    print(\"Avvio del sistema di riconoscimento automatico veicoli-animali\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Parte 1: Preparazione dei dati\n",
        "    print(\"\\nPARTE 1: PREPARAZIONE DEI DATI\")\n",
        "    print(\"-\" * 70)\n",
        "    (x_train, y_train), (x_val, y_val), (x_test, y_test), class_names = load_and_prepare_cifar10()\n",
        "    train_generator = create_data_generators(x_train, y_train)\n",
        "    visualize_augmented_samples(x_train, y_train, class_names)\n",
        "\n",
        "    # Parte 2: Addestramento del modello\n",
        "    print(\"\\nPARTE 2: ADDESTRAMENTO DEL MODELLO\")\n",
        "    print(\"-\" * 70)\n",
        "    model = create_cnn_model()\n",
        "    trained_model, history = train_model(model, train_generator, x_val, y_val)\n",
        "    visualize_training_history(history)\n",
        "\n",
        "    # Parte 3: Valutazione e predizione\n",
        "    print(\"\\nPARTE 3: VALUTAZIONE E PREDIZIONE\")\n",
        "    print(\"-\" * 70)\n",
        "    y_pred, y_true_classes, y_pred_classes = evaluate_model(trained_model, x_test, y_test, class_names)\n",
        "    visualize_incorrect_predictions(x_test, y_true_classes, y_pred_classes, class_names)\n",
        "    analyze_class_activation_maps(trained_model, x_test, y_true_classes, class_names)\n",
        "\n",
        "    # Salva il modello finale\n",
        "    trained_model.save('vehicle_animal_classifier_final.h5')\n",
        "    print(\"\\nModello finale salvato come 'vehicle_animal_classifier_final.h5'\")\n",
        "\n",
        "    print(\"\\nSistema di riconoscimento automatico completato con successo!\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}